From 0963fe320411396bf78cc3510cf755c4389daaff Mon Sep 17 00:00:00 2001
From: Dhaval Khandla <dhavaljk@ti.com>
Date: Tue, 28 Jan 2020 17:47:29 +0530
Subject: [PATCH 1/6] ntb: Add ntb_peer driver

There is a lack of driver which allows mapping of user-defined memory
regions to memory windows of NTB. So, adding this driver on top of NTB
layer to map inbound and outbound addresses to memory windows.
The inbound and outbound addresses can be passed as module parameters.
It also takes care of synchronization between the peers before setting
up address mappings.

In future, this functionality will be achieved by enhancing the
existing ntb_tool.

Signed-off-by: Dhaval Khandla <dhavaljk@ti.com>
---
 drivers/ntb/Kconfig    |  10 +
 drivers/ntb/Makefile   |   1 +
 drivers/ntb/ntb_peer.c | 407 +++++++++++++++++++++++++++++++++++++++++
 3 files changed, 418 insertions(+)
 create mode 100644 drivers/ntb/ntb_peer.c

diff --git a/drivers/ntb/Kconfig b/drivers/ntb/Kconfig
index 95944e52fa36..ca84c559e1a7 100644
--- a/drivers/ntb/Kconfig
+++ b/drivers/ntb/Kconfig
@@ -25,4 +25,14 @@ config NTB_TRANSPORT
 
 	 If unsure, say N.
 
+config NTB_PEER
+	tristate "NTB Peer Client"
+	help
+	 This is a driver that enables link setup between systems connected to NTB.
+	 It sets up the memory window address mappings for inbound as well as
+	 outbound. It takes care of synchronizing with the remote system before
+	 setting up address mappings.
+
+	 If unsure, say N.
+
 endif # NTB
diff --git a/drivers/ntb/Makefile b/drivers/ntb/Makefile
index 1921dec1949d..7325266ec5ab 100644
--- a/drivers/ntb/Makefile
+++ b/drivers/ntb/Makefile
@@ -1,2 +1,3 @@
 obj-$(CONFIG_NTB) += ntb.o hw/ test/
 obj-$(CONFIG_NTB_TRANSPORT) += ntb_transport.o
+obj-$(CONFIG_NTB_PEER) += ntb_peer.o
diff --git a/drivers/ntb/ntb_peer.c b/drivers/ntb/ntb_peer.c
new file mode 100644
index 000000000000..76e0a82f9a46
--- /dev/null
+++ b/drivers/ntb/ntb_peer.c
@@ -0,0 +1,407 @@
+// SPDX-License-Identifier: GPL-2.0
+/**
+ * Driver to setup address mappings of memory windows exposed using NTB
+ *
+ * Copyright (C) 2020 Texas Instruments
+ * Author: Dhaval Khandla <dhavaljk@ti.com>
+ */
+
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+
+#include <linux/debugfs.h>
+
+#include <linux/ntb.h>
+
+#define DEFAULT_MEMORY_WINDOW_INDEX		(1)
+#define SCRATCHPAD_STATUS_INDEX			(0)
+#define SCRATCHPAD_OFFSET_INDEX			(1)
+#define SCRATCHPAD_SIZE_INDEX			(2)
+#define SCRATCHPAD_ADDRESS_LOW_INDEX		(3)
+#define SCRATCHPAD_ADDRESS_HIGH_INDEX		(4)
+#define SCRATCHPAD_PEER_READY_INDEX		(5)
+
+#define READY_MESSAGE				(0x01234567)
+#define STATUS_READY				(1)
+
+#define MAX_WAIT_TIME				(100000)
+#define SLEEP_TIME				(20)
+
+#define RTOS_SHMEM_PEER_LOCAL_ADDRESS_LOWER	(0x00)
+#define RTOS_SHMEM_PEER_LOCAL_ADDRESS_UPPER	(0x04)
+#define RTOS_SHMEM_PCIE_ADDRESS_LOWER		(0x08)
+#define RTOS_SHMEM_PCIE_ADDRESS_UPPER		(0x0C)
+#define RTOS_SHMEM_SIZE				(0x10)
+#define RTOS_CONTROL				(0x14)
+
+#define RTOS_CONTROL_READY			(BIT(0))
+
+#define IOREMAP_SIZE				(0x18)
+
+#define BUF_LEN					(32)
+
+#define NTB_PEER_FOPS_RDWR(__name, __read, __write) \
+	const struct file_operations __name = {	\
+		.owner = THIS_MODULE,		\
+		.open = simple_open,		\
+		.read = __read,			\
+		.write = __write,		\
+	}
+
+static struct workqueue_struct *ksync_workqueue;
+static struct dentry *ntb_peer_dbgfs_topdir;
+
+static unsigned long local_shmem_address;
+module_param(local_shmem_address, ulong, 0644);
+MODULE_PARM_DESC(local_shmem_address, "Address of local shared memory");
+
+static unsigned long local_buffer_address;
+module_param(local_buffer_address, ulong, 0644);
+MODULE_PARM_DESC(local_buffer_address, "Address of local buffer memory");
+
+static int local_buffer_size;
+module_param(local_buffer_size, int, 0644);
+MODULE_PARM_DESC(local_buffer_size, "Size of local buffer memory");
+
+static unsigned long inbound_mw_address;
+module_param(inbound_mw_address, ulong, 0644);
+MODULE_PARM_DESC(inbound_mw_address, "Address of Inbound memory window");
+
+static int inbound_mw_size;
+module_param(inbound_mw_size, int, 0644);
+MODULE_PARM_DESC(inbound_mw_size, "Size of Inbound memory window");
+
+struct ntb_peer_ctx {
+	struct ntb_dev *ntb;
+	phys_addr_t outbound_mw0_base;
+	resource_size_t outbound_mw0_size;
+	struct delayed_work	sync_handler;
+	struct dentry *dbgfs_dir;
+};
+
+static ssize_t ntb_peer_spad_ready_read(struct file *filep, char __user *ubuf,
+		size_t size, loff_t *offp)
+{
+	/*
+	 * Expose a scratchpad register to user-space using debugfs to flag the
+	 * completion of local as well as peer's address region setup
+	 *
+	 * How to use: (following is the expected output after successful run)
+	 *
+	 * root@root:~# cat /sys/kernel/debug/ntb_peer/0001\:01\:00.0/spad_ready
+	 * 0x1234567
+	 */
+
+	struct ntb_peer_ctx *ctx = filep->private_data;
+	struct ntb_dev *ntb	= ctx->ntb;
+
+	char buf[BUF_LEN];
+	ssize_t pos;
+
+	if (!ntb)
+		return -EINVAL;
+
+	pos = scnprintf(buf, sizeof(buf), "%#x\n",
+		ntb_spad_read(ntb, SCRATCHPAD_PEER_READY_INDEX));
+
+	return simple_read_from_buffer(ubuf, size, offp, buf, pos);
+}
+
+static NTB_PEER_FOPS_RDWR(ntb_peer_spad_ready_fops,
+		      ntb_peer_spad_ready_read,
+		      NULL);
+
+static void ntb_peer_control_rtos(struct ntb_peer_ctx *npc,
+		phys_addr_t base_address, int size, int offset,
+		int peer_local_address_low, int peer_local_address_high)
+{
+	int ret, val;
+	void __iomem *shmem_base;
+	phys_addr_t pcie_shmem_base_address;
+	struct ntb_dev *ntb	= npc->ntb;
+	ktime_t timeout;
+	bool timedout;
+
+	/* Using ioremap to access shared memory */
+	shmem_base = ioremap_nocache(local_shmem_address,
+			(unsigned long)IOREMAP_SIZE);
+
+	if (!shmem_base)
+		return;
+
+	pcie_shmem_base_address = base_address + offset;
+
+	writel(lower_32_bits(peer_local_address_low),
+		(void *)(shmem_base + RTOS_SHMEM_PEER_LOCAL_ADDRESS_LOWER));
+	writel(upper_32_bits(peer_local_address_high),
+		(void *)(shmem_base + RTOS_SHMEM_PEER_LOCAL_ADDRESS_UPPER));
+
+	writel(lower_32_bits(pcie_shmem_base_address),
+		(void *)(shmem_base + RTOS_SHMEM_PCIE_ADDRESS_LOWER));
+	writel(upper_32_bits(pcie_shmem_base_address),
+		(void *)(shmem_base + RTOS_SHMEM_PCIE_ADDRESS_UPPER));
+
+	writel((u32)size, (void *)(shmem_base + RTOS_SHMEM_SIZE));
+
+	ret = ntb_peer_spad_write(ntb, NTB_DEF_PEER_IDX,
+			SCRATCHPAD_PEER_READY_INDEX, READY_MESSAGE);
+
+	/* Final handshake: Wait 100s for remote host (peer) to be ready*/
+	timeout = ktime_add_ms(ktime_get(), MAX_WAIT_TIME);
+	while (1) {
+		timedout = ktime_after(ktime_get(), timeout);
+
+		if (timedout)
+			break;
+
+		val = ntb_spad_read(ntb, SCRATCHPAD_PEER_READY_INDEX);
+
+		if (val == READY_MESSAGE) {
+			writel((u32)RTOS_CONTROL_READY,
+					(void *)(shmem_base + RTOS_CONTROL));
+			break;
+		}
+		msleep(SLEEP_TIME);
+	}
+
+}
+
+static int ntb_peer_set_inbound_mw(struct ntb_peer_ctx *npc,
+		u64 window_address, int window_size, int window_index)
+{
+	resource_size_t size_max, addr_align, size_align, size;
+	dma_addr_t base_address;
+	struct device *dev = &npc->ntb->dev;
+	int ret;
+
+	ret = ntb_mw_get_align(npc->ntb, NTB_DEF_PEER_IDX, window_index,
+			&addr_align, &size_align, &size_max);
+	if (ret) {
+		dev_err(dev, "Error in ntb_mw_get_align()\n");
+		return ret;
+	}
+
+	size = min_t(resource_size_t, size_max, window_size);
+	size = round_up(size, addr_align);
+	size = round_up(size, size_align);
+
+	base_address = (dma_addr_t)window_address;
+	if (!base_address) {
+		ret = -ENOMEM;
+		dev_err(dev, "Base Address for Inbound MW is NULL\n");
+		return ret;
+	}
+
+	if (!IS_ALIGNED(base_address, addr_align)) {
+		ret = -ENOMEM;
+		dev_err(dev, "Base Address for Inbound MW is not aligned properly\n");
+		return ret;
+	}
+
+	ret = ntb_mw_set_trans(npc->ntb, NTB_DEF_PEER_IDX, window_index,
+			base_address, size);
+
+	if (ret)
+		dev_err(dev, "Error in ntb_mw_set_trans()\n");
+
+	return ret;
+}
+
+static int ntb_peer_get_outbound_mw(struct ntb_peer_ctx *npc, int window_index)
+{
+	struct device *dev = &npc->ntb->dev;
+	phys_addr_t base_address;
+	resource_size_t size;
+	int ret;
+
+	ret = ntb_peer_mw_get_addr(npc->ntb, window_index, &base_address,
+			&size);
+	if (ret) {
+		dev_err(dev, "Error in ntb_peer_mw_get_addr()\n");
+		return ret;
+	}
+
+	npc->outbound_mw0_base	= base_address;
+	npc->outbound_mw0_size	= size;
+
+	return ret;
+}
+
+static void ntb_peer_sync_handler(struct work_struct *work)
+{
+	struct ntb_peer_ctx *npc = container_of(work, struct ntb_peer_ctx,
+			sync_handler.work);
+	struct ntb_dev *ntb	= npc->ntb;
+	struct device *dev = &ntb->dev;
+	ktime_t timeout;
+	bool timedout;
+	int ret, val, size, low_addr, high_addr;
+
+	ret = ntb_peer_set_inbound_mw(npc, inbound_mw_address, inbound_mw_size,
+			DEFAULT_MEMORY_WINDOW_INDEX);
+	if (ret) {
+		dev_err(dev, "Error in ntb_peer_set_inbound_mw()\n");
+		return;
+	}
+
+	ret = ntb_spad_write(ntb, SCRATCHPAD_OFFSET_INDEX,
+			local_buffer_address - inbound_mw_address);
+	ret = ntb_spad_write(ntb, SCRATCHPAD_SIZE_INDEX, local_buffer_size);
+	ret = ntb_spad_write(ntb, SCRATCHPAD_ADDRESS_LOW_INDEX,
+			lower_32_bits(local_buffer_address));
+	ret = ntb_spad_write(ntb, SCRATCHPAD_ADDRESS_HIGH_INDEX,
+			upper_32_bits(local_buffer_address));
+	ret = ntb_spad_write(ntb, SCRATCHPAD_STATUS_INDEX, STATUS_READY);
+
+	/* Initial handshake: Wait 100s for remote host (peer) to be ready */
+
+	timeout = ktime_add_ms(ktime_get(), MAX_WAIT_TIME);
+	while (1) {
+		timedout = ktime_after(ktime_get(), timeout);
+
+		if (timedout)
+			break;
+		val = ntb_peer_spad_read(ntb, NTB_DEF_PEER_IDX,
+				SCRATCHPAD_STATUS_INDEX);
+
+		if (val == STATUS_READY) {
+			val = ntb_peer_spad_read(ntb, NTB_DEF_PEER_IDX,
+					SCRATCHPAD_OFFSET_INDEX);
+			size = ntb_peer_spad_read(ntb, NTB_DEF_PEER_IDX,
+					SCRATCHPAD_SIZE_INDEX);
+			low_addr = ntb_peer_spad_read(ntb, NTB_DEF_PEER_IDX,
+					SCRATCHPAD_ADDRESS_LOW_INDEX);
+			high_addr = ntb_peer_spad_read(ntb, NTB_DEF_PEER_IDX,
+					SCRATCHPAD_ADDRESS_HIGH_INDEX);
+
+			ntb_peer_control_rtos(npc, npc->outbound_mw0_base,
+					size, val, low_addr, high_addr);
+			break;
+		}
+		msleep(SLEEP_TIME);
+	}
+}
+
+static void ntb_peer_link_event(void *ctx)
+{
+	struct ntb_peer_ctx *npc = ctx;
+
+	queue_work(ksync_workqueue, &npc->sync_handler.work);
+}
+
+static void ntb_peer_db_event(void *ctx, int vec)
+{
+}
+
+static void ntb_peer_msg_event(void *ctx)
+{
+}
+
+static const struct ntb_ctx_ops ntb_peer_ops = {
+	.link_event = ntb_peer_link_event,
+	.db_event = ntb_peer_db_event,
+	.msg_event = ntb_peer_msg_event
+};
+
+static void ntb_peer_setup_dbgfs(struct ntb_peer_ctx *npc)
+{
+	if (!ntb_peer_dbgfs_topdir) {
+		npc->dbgfs_dir = NULL;
+		return;
+	}
+
+	npc->dbgfs_dir = debugfs_create_dir(dev_name(&npc->ntb->dev),
+					   ntb_peer_dbgfs_topdir);
+	if (!npc->dbgfs_dir)
+		return;
+
+	debugfs_create_file("spad_ready", 0600, npc->dbgfs_dir,
+			    npc, &ntb_peer_spad_ready_fops);
+}
+
+static void ntb_peer_clear_dbgfs(struct ntb_peer_ctx *npc)
+{
+	debugfs_remove_recursive(npc->dbgfs_dir);
+}
+
+static int ntb_peer_probe(struct ntb_client *self, struct ntb_dev *ntb)
+{
+	struct ntb_peer_ctx *npc;
+	struct device *dev = &ntb->dev;
+	int ret;
+
+	npc = devm_kzalloc(&ntb->dev, sizeof(*npc), GFP_KERNEL);
+	if (npc == NULL)
+		return -ENOMEM;
+
+	npc->ntb = ntb;
+
+	ntb_set_ctx(npc->ntb, npc, &ntb_peer_ops);
+
+	ntb_peer_setup_dbgfs(npc);
+
+	ret = ntb_peer_get_outbound_mw(npc, DEFAULT_MEMORY_WINDOW_INDEX);
+	if (ret) {
+		dev_err(dev, "Error in ntb_peer_set_inbound_mw()\n");
+		return ret;
+	}
+
+	/* Initialize sync handler */
+	INIT_DELAYED_WORK(&npc->sync_handler, ntb_peer_sync_handler);
+
+	/* Establish the link */
+	ret = ntb_link_enable(ntb, NTB_SPEED_AUTO, NTB_WIDTH_AUTO);
+	if (ret)
+		dev_err(dev, "Failed to establish link\n");
+
+	return ret;
+}
+
+static void ntb_peer_remove(struct ntb_client *self, struct ntb_dev *ntb)
+{
+	struct ntb_peer_ctx *npc = ntb->ctx;
+
+	cancel_delayed_work(&npc->sync_handler);
+
+	ntb_clear_ctx(npc->ntb);
+	ntb_link_disable(npc->ntb);
+
+	ntb_peer_clear_dbgfs(npc);
+}
+
+static struct ntb_client ntb_peer_client = {
+	.ops = {
+		.probe = ntb_peer_probe,
+		.remove = ntb_peer_remove,
+	}
+};
+
+static int __init ntb_peer_init(void)
+{
+	int ret;
+
+	ksync_workqueue = alloc_workqueue("koutbound_setup",
+					     WQ_MEM_RECLAIM | WQ_HIGHPRI, 0);
+
+	if (debugfs_initialized())
+		ntb_peer_dbgfs_topdir = debugfs_create_dir(KBUILD_MODNAME,
+				NULL);
+
+	ret = ntb_register_client(&ntb_peer_client);
+	if (ret)
+		debugfs_remove_recursive(ntb_peer_dbgfs_topdir);
+
+	return ret;
+}
+module_init(ntb_peer_init);
+
+static void __exit ntb_peer_exit(void)
+{
+	ntb_unregister_client(&ntb_peer_client);
+	debugfs_remove_recursive(ntb_peer_dbgfs_topdir);
+}
+module_exit(ntb_peer_exit);
+
+MODULE_DESCRIPTION("PCIe Peer Client Driver");
+MODULE_LICENSE("GPL v2");
-- 
2.17.1

